
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>The multilayer perceptron &#8212; A Primer on the Mathematical Foundations of Deep Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '00_the_mlp';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The multilayer perceptron, a universal approximator" href="01_mlp_universal_approx.html" />
    <link rel="prev" title="A Primer on the Mathematical Foundations of Deep Learning" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="intro.html">

  
  
  
  
  
  
  

  
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        The multilayer perceptron
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="01_mlp_universal_approx.html">
                        The multilayer perceptron, a universal approximator
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="02_deep_vs_shallow.html">
                        Deep vs shallow
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="03_sgd_and_bias_variance.html">
                        SGD guarantees & the bias–variance trade-off
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="04_invariance_robustness.html">
                        Invariance & robustness
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="05_equivariance_and_cnns.html">
                        Equivariance & convolutional neural networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="06_loss_landscape_normalization_resnets.html">
                        The loss landscape: Normalization & Residual Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="07_input_convex_neural_nets.html">
                        Input-convex neural networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="08_autoencoder.html">
                        Autoencoders
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="09_variational_autoencoder.html">
                        Variational autoencoders
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="10_GANs.html">
                        Generative adversarial networks (GANs)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="11_diffusion_models.html">
                        Score-based models
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        The multilayer perceptron
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="01_mlp_universal_approx.html">
                        The multilayer perceptron, a universal approximator
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="02_deep_vs_shallow.html">
                        Deep vs shallow
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="03_sgd_and_bias_variance.html">
                        SGD guarantees & the bias–variance trade-off
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="04_invariance_robustness.html">
                        Invariance & robustness
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="05_equivariance_and_cnns.html">
                        Equivariance & convolutional neural networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="06_loss_landscape_normalization_resnets.html">
                        The loss landscape: Normalization & Residual Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="07_input_convex_neural_nets.html">
                        Input-convex neural networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="08_autoencoder.html">
                        Autoencoders
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="09_variational_autoencoder.html">
                        Variational autoencoders
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="10_GANs.html">
                        Generative adversarial networks (GANs)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="11_diffusion_models.html">
                        Score-based models
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="intro.html">

  
  
  
  
  
  
  

  
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    A Primer on the Mathematical Foundations of Deep Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">The multilayer perceptron</a></li>
<li class="toctree-l1"><a class="reference internal" href="01_mlp_universal_approx.html">The multilayer perceptron, a universal approximator</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_deep_vs_shallow.html">Deep vs shallow</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_sgd_and_bias_variance.html">SGD guarantees &amp; the bias–variance trade-off</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_invariance_robustness.html">Invariance &amp; robustness</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_equivariance_and_cnns.html">Equivariance &amp; convolutional neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_loss_landscape_normalization_resnets.html">The loss landscape: Normalization &amp; Residual Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_input_convex_neural_nets.html">Input-convex neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_autoencoder.html">Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_variational_autoencoder.html">Variational autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_GANs.html">Generative adversarial networks (GANs)</a></li>

<li class="toctree-l1"><a class="reference internal" href="11_diffusion_models.html">Score-based models</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">


<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://colab.research.google.com/v2/gh/sdittmer/mathematical_foundations_of_deep_learning/master?urlpath=tree/docs/00_the_mlp.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</a>
      
  </ul>
</div>

<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="_sources/00_the_mlp.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The multilayer perceptron</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-the-multilayer-preceptron">
   What is the multilayer preceptron?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-regression">
     Linear regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-multilayer-preceptron-or-what-is-deep-learning">
     The multilayer preceptron; or, what is deep learning?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-training-of-deep-models">
   The training of deep models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-problem">
     The problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-solution-stochastic-gradient-descent-with-a-validation-set">
     A solution: Stochastic gradient descent with a validation set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-regression-example">
     A regression Example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#define-dataset">
       Define dataset
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#define-simple-mlp">
       Define simple MLP
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#instantiate-objects-for-training">
       Instantiate objects for training
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-training">
       Run training
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#plot-training-losses">
       Plot training losses
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#evaluate-the-model">
       Evaluate the model
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-classification-example">
     A classification Example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Define simple MLP
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Instantiate objects for training
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Run training
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Plot training losses
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Evaluate the model
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="the-multilayer-perceptron">
<h1>The multilayer perceptron<a class="headerlink" href="#the-multilayer-perceptron" title="Permalink to this headline">#</a></h1>
<p>This lecture will give an overview of the simples <strong>deep learning</strong> (DL) model, the <strong>multilayer perceptron</strong> (MLP).</p>
<p>We will try to answer: What is an MLP and how to train it?</p>
<section id="what-is-the-multilayer-preceptron">
<h2>What is the multilayer preceptron?<a class="headerlink" href="#what-is-the-multilayer-preceptron" title="Permalink to this headline">#</a></h2>
<section id="linear-regression">
<h3>Linear regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">#</a></h3>
<p>We begin, by reviewing the (affine) <strong>linear regression</strong>. Linear regression is a model</p>
<div class="math notranslate nohighlight">
\[f_\Theta: \mathbb{R}^n \ni x \to y \in \mathbb{R}^m\]</div>
<p>given by</p>
<div class="math notranslate nohighlight">
\[y = Ax + b,\]</div>
<p>where <span class="math notranslate nohighlight">\(A\in\mathbb{R}^{m\times n}\)</span> and <span class="math notranslate nohighlight">\(b\in\mathbb{R}^m\)</span> comprise the parameters <span class="math notranslate nohighlight">\(\Theta = (A, b)\)</span>.</p>
<p>Given a dataset <span class="math notranslate nohighlight">\(\mathscr{D} =\{(x_i,y_i)\}_{i=1}^N\)</span> of realizations <span class="math notranslate nohighlight">\((x_i, y_i)\sim p_{X,Y}\)</span> one can train the linear regression via minimising the mean squared error (MSE), i.e., by solving</p>
<div class="math notranslate nohighlight">
\[\Theta^* = \arg\min_{\Theta} \frac{1}{N} \sum_i \|f_\Theta(x_i) - y_i\|_2^2.\]</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;matplotlib.font_manager&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">η</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span>
<span class="n">yδ</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">η</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yδ</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yδ</span><span class="p">,</span> <span class="s1">&#39;go&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original data&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fitted line&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/ce2cdd4b01659e325c4d9cd324d186c419695f59b07c3df4a12e17e639d83622.png" src="_images/ce2cdd4b01659e325c4d9cd324d186c419695f59b07c3df4a12e17e639d83622.png" />
</div>
</div>
<p>Unsurprisingly linear regression is a tool for solving regression problems. If we want to solve classification problems, we can use a modification of linear regression, <strong>logistic regression</strong>.</p>
</section>
<section id="logistic-regression">
<h3>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">#</a></h3>
<p>We can define logistic regression via linear regression as</p>
<div class="math notranslate nohighlight">
\[g_\Theta: \mathbb{R}^n \ni x \mapsto (s \circ f_\Theta)(x) \in \mathbb{R}^m,\]</div>
<p>where <span class="math notranslate nohighlight">\(s: \mathbb{R} \to \mathbb{R}\)</span> is the pointwise applied logistic function (often called sigmoid) defined as</p>
<div class="math notranslate nohighlight">
\[s(x) = \frac{1}{1+\exp -x}.\]</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;s(x)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">s</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/8a3406c77655a8632b0e9523daf8b19f72aef65fd939f399533c2042f8ce75ac.png" src="_images/8a3406c77655a8632b0e9523daf8b19f72aef65fd939f399533c2042f8ce75ac.png" />
</div>
</div>
<p>In principle, one could also train logistic regression via the MSE. For reasons based on <a class="reference external" href="https://en.wikipedia.org/wiki/Bernoulli_distribution?oldformat=true">Bernoulli variables</a> though, it is better to train the model via the binary cross-entropy (BCE). The BCE is defined as follows:</p>
<div class="math notranslate nohighlight">
\[\mbox{BCE}(\hat y, y) = -y \log \hat y - (1-y) \log(1 - \hat y)\]</div>
<p>I.e., we train via</p>
<div class="math notranslate nohighlight">
\[\Theta^* = \arg\min_{\Theta} \frac{1}{N} \sum_i \mbox{BCE}(f_\Theta(x_i), y_i).\]</div>
</section>
<section id="the-multilayer-preceptron-or-what-is-deep-learning">
<h3>The multilayer preceptron; or, what is deep learning?<a class="headerlink" href="#the-multilayer-preceptron-or-what-is-deep-learning" title="Permalink to this headline">#</a></h3>
<p>We call DL “deep” simply because it discusses deep models, in the sense that one concatenates mutiple simple/shallow models. The first deep learning model was the MLP. The classical MLP is simply a concatenation of logistic regression models. I.e.,</p>
<div class="math notranslate nohighlight">
\[\phi_\Theta = h \circ g_{\Theta_{L-1}} \circ \cdots \circ g_{\Theta_1},\]</div>
<p>with <span class="math notranslate nohighlight">\(\Theta = \{\Theta_i\}_i\)</span> and <span class="math notranslate nohighlight">\(h\)</span> either also a logistic regression model or a linear regression, depending on whether one wants to use the MLP for classification or regression. We can also train these models with the MSE or BCE loss discussed above.</p>
<p>While we defined the MLP using the sigmoid function as the so-called <strong>activation function</strong>, nowadays MLPs are defined more general as</p>
<div class="math notranslate nohighlight">
\[\phi_\Theta = \phi^{(L)} \circ \cdots \circ \phi^{(1)},\]</div>
<p>with the <span class="math notranslate nohighlight">\(\phi_i\)</span> being the so-called layers of the network defined as</p>
<div class="math notranslate nohighlight">
\[\phi^{(i)}(x) = f_i(A_i x + b_i)\]</div>
<p>with <span class="math notranslate nohighlight">\(f_i\)</span> being some kind of non-linear function – the so-called activation function –  e.g., sigmoid, and the trainable parameters <span class="math notranslate nohighlight">\(A_i\in\mathbb{R}^{n_{i-1} \times n_i}\)</span> and <span class="math notranslate nohighlight">\(b_i\in\mathbb{R}^{n_i}\)</span>. Here we have <span class="math notranslate nohighlight">\(n_0 = n\)</span> the dimension of <span class="math notranslate nohighlight">\(x\in\mathbb{R}^n\)</span> and <span class="math notranslate nohighlight">\(n_L=m\)</span> the dimension of <span class="math notranslate nohighlight">\(y \in \mathbb{R}^m\)</span>:</p>
<p>For different reasons, e.g., the <a class="reference external" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem?oldformat=true">vanishing gradients problem</a>, today, sigmoid functions are practically only used in the last layer. Two “standard choices” for activation functions are</p>
<div class="math notranslate nohighlight">
\[\mbox{ReLU} (x) = \max(0, x)\]</div>
<p>and the hyperbolic tangent.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
<span class="n">t</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">r</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">t</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">r</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ReLU&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/b3f4b17c619cd7569625b592a7bb81e3011e73da7656ff880bc4b275319d7c28.png" src="_images/b3f4b17c619cd7569625b592a7bb81e3011e73da7656ff880bc4b275319d7c28.png" />
</div>
</div>
</section>
</section>
<section id="the-training-of-deep-models">
<h2>The training of deep models<a class="headerlink" href="#the-training-of-deep-models" title="Permalink to this headline">#</a></h2>
<section id="the-problem">
<h3>The problem<a class="headerlink" href="#the-problem" title="Permalink to this headline">#</a></h3>
<p>While we now know what an MLP is, we have not discussed how to choose its weights <span class="math notranslate nohighlight">\(\Theta\)</span>, i.e., how to train its weights <span class="math notranslate nohighlight">\(A_i\)</span> and biases <span class="math notranslate nohighlight">\(b_i\)</span>.</p>
<p>for a given loss function
<span class="math notranslate nohighlight">\(\mathscr{l}:Y\times Y \to \mathbb{R},\)</span>
e.g., with and <span class="math notranslate nohighlight">\(Y=\mathbb{R}^n\)</span> we can define the general so-called <strong>loss or empirical risk</strong> as</p>
<div class="math notranslate nohighlight">
\[L(\Theta) = \frac{1}{|\mathscr{D}|}\sum_{(x,y)\in\mathscr{D}} \mathscr{l}(\phi_\Theta(x), y).\]</div>
<p>This is simply the generalization of what we discuss before where we made the common choices of <span class="math notranslate nohighlight">\(\mathscr{l} = \mbox{MSE}\)</span> and <span class="math notranslate nohighlight">\(\mathscr{l}= \mbox{BCE}\)</span>.</p>
<p>The goal of training the model is to find a <span class="math notranslate nohighlight">\(\Theta\)</span> that minimizes the true risk defined as</p>
<div class="math notranslate nohighlight">
\[L^*(\Theta) = \mathbb{E}_{(x,y)\sim p_{X,Y}} \mathscr{l}(\phi_\Theta(x), y).\]</div>
<p>Unfortunately, we do not have access to the whole distribution, only the samples in <span class="math notranslate nohighlight">\(\mathscr{D}\)</span>; therefore, as a surrogate, we try to find a <span class="math notranslate nohighlight">\(\Theta\)</span> that leads to small values of <span class="math notranslate nohighlight">\(L(\Theta)\)</span> and makes us hopeful, that also <span class="math notranslate nohighlight">\(L^*(\Theta)\)</span> is small.</p>
<p>To do that, we can not simply minimize <span class="math notranslate nohighlight">\(L(\Theta)\)</span> as much as possible. If the MLP/neural network is <em>large enough</em>, it could simply overfit, i.e., memorize all data points of <span class="math notranslate nohighlight">\(\mathscr{D}\)</span> in its parameters <span class="math notranslate nohighlight">\(\Theta\)</span>. This would minimize <span class="math notranslate nohighlight">\(L\)</span>, but we have no idea whether it also leads to small values of <span class="math notranslate nohighlight">\(L^*\)</span>.</p>
</section>
<section id="a-solution-stochastic-gradient-descent-with-a-validation-set">
<h3>A solution: Stochastic gradient descent with a validation set<a class="headerlink" href="#a-solution-stochastic-gradient-descent-with-a-validation-set" title="Permalink to this headline">#</a></h3>
<p>The most common solution to this problem starts by splitting the dataset into a disjoint training, validation, and test set. We will denote this partitioning via</p>
<div class="math notranslate nohighlight">
\[\mathscr{D} = \mathscr{D}_\text{train} \cup \mathscr{D}_\text{valid} \cup \mathscr{D}_\text{test}.\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The split of the sets should almost always be random.</p>
</div>
<p>One then minimizes the empirical loss based on the empirical risk on over the training dataset, i.e.,</p>
<div class="math notranslate nohighlight">
\[L(\Theta, \mathscr{D}_\text{train}) = \frac{1}{|\mathscr{D}_\text{train}|}\sum_{(x,y)\in\mathscr{D}_\text{train}} \mathscr{l}(\phi_\Theta(x), y),\]</div>
<p>via stochastic gradient descent.</p>
<p>The idea of stochastic gradient descent (SGD) is the following:</p>
<ol class="arabic simple">
<li><p>Sample <span class="math notranslate nohighlight">\(k\)</span> random samples from <span class="math notranslate nohighlight">\(\mathscr{D}_\text{train}\)</span>. These samples comprise a <strong>batch</strong> <span class="math notranslate nohighlight">\(B\subset \mathscr{D}_\text{train}\)</span> of size <span class="math notranslate nohighlight">\(k\)</span>.</p></li>
<li><p>Compute the gradient <span class="math notranslate nohighlight">\(\nabla_\Theta L(\Theta, B)\)</span>.</p></li>
<li><p>Take a <a class="reference external" href="https://en.wikipedia.org/wiki/Gradient_descent?oldformat=true">gradient step</a> for some predefined step size (also called learning rate) <span class="math notranslate nohighlight">\(\eta\)</span>, i.e., update/reassign <span class="math notranslate nohighlight">\(\Theta \leftarrow \Theta - \eta \nabla_\Theta L(\Theta, B).\)</span></p></li>
<li><p>Usually go to 1., but <em>from time to time</em>, e.g., after every 100 repetitions, go to 5.</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(L(\Theta, \mathscr{D}_\text{valid})\)</span>. If you have previously computed this for earlier parameters, compare the value. If the value has not decreased, stop the training. Otherwise, go to 1.</p></li>
</ol>
<p>If after the training <span class="math notranslate nohighlight">\(L(\Theta, \mathscr{D}_\text{train})\)</span> and <span class="math notranslate nohighlight">\(L(\Theta, \mathscr{D}_\text{valid})\)</span> are small, we can have some confidence, that our model generalizes, i.e., achives small values for the true risk. To estimate the value of the true risk we can now compute <span class="math notranslate nohighlight">\(L(\Theta, \mathscr{D}_\text{test})\)</span>.</p>
</section>
<section id="a-regression-example">
<h3>A regression Example<a class="headerlink" href="#a-regression-example" title="Permalink to this headline">#</a></h3>
<p>We will train a simple neural network to fit the function</p>
<div class="math notranslate nohighlight">
\[f: [-\pi, \pi] \ni x \mapsto \cos(x).\]</div>
<p>We begin by creating a noisy training dataset with 300 samples and split it into training, validation, and test set.</p>
<section id="define-dataset">
<h4>Define dataset<a class="headerlink" href="#define-dataset" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">xs</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>

<span class="n">xs_train</span><span class="p">,</span> <span class="n">ys_train</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:</span><span class="mi">128</span><span class="p">],</span> <span class="n">ys</span><span class="p">[:</span><span class="mi">128</span><span class="p">]</span>
<span class="n">xs_valid</span><span class="p">,</span> <span class="n">ys_valid</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="mi">128</span><span class="p">:],</span> <span class="n">ys</span><span class="p">[</span><span class="mi">128</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;The training data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs_train</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">ys_train</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/396fa1a68e5147eedac2173b51069ce96866384810a7ce51ec7c8b7cceea6210.png" src="_images/396fa1a68e5147eedac2173b51069ce96866384810a7ce51ec7c8b7cceea6210.png" />
</div>
</div>
</section>
<section id="define-simple-mlp">
<h4>Define simple MLP<a class="headerlink" href="#define-simple-mlp" title="Permalink to this headline">#</a></h4>
<p>We then define a simple two layer MLP.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleMLP</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">final_act</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_act</span> <span class="o">=</span> <span class="n">final_act</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
        <span class="n">zs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">zs</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ys</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="instantiate-objects-for-training">
<h4>Instantiate objects for training<a class="headerlink" href="#instantiate-objects-for-training" title="Permalink to this headline">#</a></h4>
<p>We use the MSE as our loss and create an instance of the model class and create a SGD optimizer with a step size of <span class="math notranslate nohighlight">\(10^{-2}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleMLP</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">final_act</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">())</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-training">
<h4>Run training<a class="headerlink" href="#run-training" title="Permalink to this headline">#</a></h4>
<p>We then start the train with a batch size of <span class="math notranslate nohighlight">\(8\)</span> and <span class="math notranslate nohighlight">\(5000\)</span> training steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_train_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs_train</span><span class="p">))[:</span><span class="n">batch_size</span><span class="p">]</span>

    <span class="n">xs_batch</span> <span class="o">=</span> <span class="n">xs_train</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
    <span class="n">ys_batch</span> <span class="o">=</span> <span class="n">ys_train</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">xs_batch</span><span class="p">,</span> <span class="n">ys_batch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interval_eval</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">losses_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">losses_valid</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
    <span class="n">xs_batch</span><span class="p">,</span> <span class="n">ys_batch</span> <span class="o">=</span> <span class="n">get_train_batch</span><span class="p">()</span>

    <span class="n">ys_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xs_batch</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_batch</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">interval_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">loss_train</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xs_train</span><span class="p">),</span> <span class="n">ys_train</span><span class="p">)</span>
        <span class="n">loss_valid</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xs_valid</span><span class="p">),</span> <span class="n">ys_valid</span><span class="p">)</span>
        <span class="n">losses_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_train</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">losses_valid</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_valid</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-training-losses">
<h4>Plot training losses<a class="headerlink" href="#plot-training-losses" title="Permalink to this headline">#</a></h4>
<p>Plot the training and validation loss over the course of the training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">interval_eval</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses_train</span><span class="p">),</span> <span class="n">interval_eval</span><span class="p">),</span> <span class="n">losses_train</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;training losses&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">interval_eval</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses_valid</span><span class="p">),</span> <span class="n">interval_eval</span><span class="p">),</span> <span class="n">losses_valid</span><span class="p">,</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;validation losses&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5e1ea67e88c2467fc95f20118a3c94696c33792cb22d563af737e7bb8d097255.png" src="_images/5e1ea67e88c2467fc95f20118a3c94696c33792cb22d563af737e7bb8d097255.png" />
</div>
</div>
</section>
<section id="evaluate-the-model">
<h4>Evaluate the model<a class="headerlink" href="#evaluate-the-model" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">ts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
<span class="n">gt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Thresholded predictions on training set.&quot;</span><span class="p">)</span>
<span class="n">ys_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xs_train</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs_train</span><span class="p">,</span> <span class="n">ys_hat</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ground truth&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Thresholded predictions on validation set.&quot;</span><span class="p">)</span>
<span class="n">ys_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xs_valid</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs_valid</span><span class="p">,</span> <span class="n">ys_hat</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ground truth&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/85af468bebe0d083640ae75fc10b0d9f6b8f7835b2f755f59b20b20167e3a625.png" src="_images/85af468bebe0d083640ae75fc10b0d9f6b8f7835b2f755f59b20b20167e3a625.png" />
</div>
</div>
</section>
</section>
<section id="a-classification-example">
<h3>A classification Example<a class="headerlink" href="#a-classification-example" title="Permalink to this headline">#</a></h3>
<p>We proceed analogous to the regression task above. The task is to classfiy whether a point <span class="math notranslate nohighlight">\(x\in[0,1]^2\)</span> lies left or right of the line <span class="math notranslate nohighlight">\(x_1=0.5\)</span>. Again, we begin by creating the dataset.</p>
<section id="id1">
<h4>Define simple MLP<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:,:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>

<span class="n">xs_train</span><span class="p">,</span> <span class="n">ys_train</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[:</span><span class="mi">128</span><span class="p">],</span> <span class="n">ys</span><span class="p">[:</span><span class="mi">128</span><span class="p">]</span>
<span class="n">xs_valid</span><span class="p">,</span> <span class="n">ys_valid</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="mi">128</span><span class="p">:],</span> <span class="n">ys</span><span class="p">[</span><span class="mi">128</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;The training data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">xs_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">ys_train</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3a2294b2b4344adbe4edb47d559276182ec0fb99b6d0240a5cddb5ae8100593d.png" src="_images/3a2294b2b4344adbe4edb47d559276182ec0fb99b6d0240a5cddb5ae8100593d.png" />
</div>
</div>
</section>
<section id="id2">
<h4>Instantiate objects for training<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h4>
<p>We will use similar network to the one used for the resesstion task, but we will use the BCE loss instead of the MSE.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleMLP</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">final_act</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h4>Run training<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h4>
<p>We then start the train with a batch size of <span class="math notranslate nohighlight">\(8\)</span> and <span class="math notranslate nohighlight">\(20000\)</span> training steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_train_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs_train</span><span class="p">))[:</span><span class="n">batch_size</span><span class="p">]</span>

    <span class="n">xs_batch</span> <span class="o">=</span> <span class="n">xs_train</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
    <span class="n">ys_batch</span> <span class="o">=</span> <span class="n">ys_train</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">xs_batch</span><span class="p">,</span> <span class="n">ys_batch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interval_eval</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">losses_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">losses_valid</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
    <span class="n">xs_batch</span><span class="p">,</span> <span class="n">ys_batch</span> <span class="o">=</span> <span class="n">get_train_batch</span><span class="p">()</span>

    <span class="n">ys_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xs_batch</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">ys_hat</span><span class="p">,</span> <span class="n">ys_batch</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">interval_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">loss_train</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xs_train</span><span class="p">),</span> <span class="n">ys_train</span><span class="p">)</span>
        <span class="n">loss_valid</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xs_valid</span><span class="p">),</span> <span class="n">ys_valid</span><span class="p">)</span>
        <span class="n">losses_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_train</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">losses_valid</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_valid</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h4>Plot training losses<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h4>
<p>Plot the training and validation loss over the course of the training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">interval_eval</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses_train</span><span class="p">),</span> <span class="n">interval_eval</span><span class="p">),</span> <span class="n">losses_train</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;training losses&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">interval_eval</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses_valid</span><span class="p">),</span> <span class="n">interval_eval</span><span class="p">),</span> <span class="n">losses_valid</span><span class="p">,</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;validation losses&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7d4bae3b2604bce9cec2c72c44e0ef8bace98a7124b6328c274412b57ea042ce.png" src="_images/7d4bae3b2604bce9cec2c72c44e0ef8bace98a7124b6328c274412b57ea042ce.png" />
</div>
</div>
</section>
<section id="id5">
<h4>Evaluate the model<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Thresholded predictions on training set.&quot;</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xs_train</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">xs_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_hat</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Thresholded predictions on validation set.&quot;</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xs_valid</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs_valid</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">xs_valid</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_hat</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b6172afa4598ff6f4e0f217cef96da65f4b3bc09336bbddbc55995050812299f.png" src="_images/b6172afa4598ff6f4e0f217cef96da65f4b3bc09336bbddbc55995050812299f.png" />
</div>
</div>
</section>
</section>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>In the training above, we did neither use early stopping nor the test set for evaluation. Implement these two omissions.</p></li>
<li><p>What is a better choice for the final activation functions in the regression task?</p></li>
</ul>
<div class="toggle docutils container">
<p>The <span class="math notranslate nohighlight">\(\tanh\)</span> function. It makes the output smoother and restricts it into the <span class="math notranslate nohighlight">\([-1, 1]\)</span> interval.</p>
</div>
<ul class="simple">
<li><p>Train our simple MLP on the MNIST or FashionMNIST dataset. Follow the <a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">PyTorch: A 60 Minute Blitz</a> for advice.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">A Primer on the Mathematical Foundations of Deep Learning</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="01_mlp_universal_approx.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">The multilayer perceptron, a universal approximator</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-the-multilayer-preceptron">
   What is the multilayer preceptron?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-regression">
     Linear regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-multilayer-preceptron-or-what-is-deep-learning">
     The multilayer preceptron; or, what is deep learning?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-training-of-deep-models">
   The training of deep models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-problem">
     The problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-solution-stochastic-gradient-descent-with-a-validation-set">
     A solution: Stochastic gradient descent with a validation set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-regression-example">
     A regression Example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#define-dataset">
       Define dataset
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#define-simple-mlp">
       Define simple MLP
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#instantiate-objects-for-training">
       Instantiate objects for training
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-training">
       Run training
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#plot-training-losses">
       Plot training losses
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#evaluate-the-model">
       Evaluate the model
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-classification-example">
     A classification Example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Define simple MLP
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Instantiate objects for training
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Run training
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Plot training losses
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Evaluate the model
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sören Dittmer
</p>

  </div>
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>